# 验证报告（Codex）
日期：2025-12-30  
执行者：Codex

## 覆盖范围
- 设置页：新增“语音识别（ASR）”分页，暴露关键参数并提供说明
- SenseVoice-ASR：新增 WebSocket 实时识别（FSMN-VAD 端点检测 + SenseVoiceSmall 转写），并更新网页 DEMO
- ChatWindow：ASR 启用后自动监听麦克风；识别结果可配置为“直接发送”或“仅在输入框”
- Live2D 右键菜单：新增“语音识别（ASR）”开关
- 设置页：支持刷新并选择麦克风（`asr.micDeviceId`）

## 本地自动验证
- `npx tsc -p tsconfig.json --noEmit`：通过
- `npm run lint`：通过

## 手动验证步骤（建议）
1) 运行 `NeoDeskPet-electron/SenseVoice-ASR/start_sensevoice_demo.bat`
2) 打开 `http://127.0.0.1:8766`
3) 点击“开始监听”，说话 -> 停顿（约 0.8s 默认），应返回一条识别结果
4) 调大/调小“尾部静音判停 / 最短语音段”，观察是否更贴合你的说话习惯
5) 打开桌宠聊天窗口 -> 设置 -> 语音识别：
   - 开启语音识别后应自动开始监听
   - 选择“仅在输入框”时，识别结果应自动写入输入框
   - 选择“直接发送”时，识别结果应直接触发发送并得到 LLM 回复

## 风险与注意事项
- Web DEMO 使用 `ScriptProcessorNode` 采集音频，兼容性好但延迟略高；如果你后续需要更低延迟，可改 AudioWorklet（不影响服务端协议）。
- 长时间持续说话会触发“最长语音段”强制切分（默认 15s）以避免一直不出结果，可在设置/DEMO 中调整。
- Electron 内部同样使用 `ScriptProcessorNode`，后续如需更低延迟/更稳定，可再迁移到 AudioWorklet（功能不变）。

---

## 记忆系统（2025-12-31）

### 本地自动验证
- `cd g:\DeskPet\NeoDeskPet-electron; npm run lint`：通过
- `cd g:\DeskPet\NeoDeskPet-electron; npx tsc -p tsconfig.json --noEmit`：通过

### 手动验证步骤（建议）
1) 打开聊天窗口，确认 header 下方出现“记忆状态栏”（采集/召回/自动提炼开关 + 有效消息数/cursor/上次提炼信息）。
2) 连续发送多轮对话，并观察“距离下次自动提炼还差 N 条”随对话推进递减。
3) 若启用 TTS 分句导致连续多条 assistant 消息，确认“有效消息数”以“合并连续 assistant 为 1 条”的口径计算，避免频繁触发。
4) 右键聊天窗口空白处，点击“一键总结（写入长期记忆）”，确认写入条数与“上次提炼时间/写入条数/失败原因”展示同步刷新。
5) 打开记忆控制台，切换到对应会话，确认提炼区状态行同样展示“有效数/cursor/还差 N/上次提炼结果”并与聊天窗口一致。
6) 在记忆控制台勾选“写入到当前筛选人设”等选项后关闭窗口再打开，确认设置可持久化保留。

### M2 验证（建议）
1) 打开记忆控制台，确认列表每条记忆新增展示：`status/ret/imp/str/hit/last/type/src/pin`。
2) 在聊天里用关键词提问触发召回，再回到记忆控制台刷新：命中的记忆应出现 `hit+1`、`last` 更新、`str` 上升（并且若之前为 archived，会回到 active）。
3) 重启应用后观察控制台：较久未访问的记忆 `ret` 会自然变低，必要时会被维护任务标记为 `archived`（命中后会自动回到 active）。
4) 用“模糊问法”测试：先发“我要吃手抓羊肉”，再问“还记得手抓羊肉吗”，命中应发生在“我要吃手抓羊肉”这条上（而不是必须完全相同句子）。
5) 触发“待处理队列”测试：
   - 先在设置/控制台手动添加一条长期记忆（例如“最爱吃：手抓羊肉”）。
   - 再添加一条非常相似但不完全相同的记忆（例如“最爱吃：烤羊腿”或“最爱吃：手抓羊肉（新疆）”）。
   - 打开记忆控制台的“待处理（冲突/合并）”，应出现 update/merge 条目，并可点击 采用新/保留两条/合并/忽略。
6) 版本与回滚测试：
   - 在记忆列表点击某条记忆，在“当前记忆（编辑/版本/回滚）”里修改内容并保存。
   - 确认出现一条新的版本记录；点击“回滚到旧内容”，确认内容恢复且版本记录继续增长。

### M4 验证（建议）
1) 打开记忆控制台 -> “筛选与刷新”：切换 `状态/置顶/来源/类型/排序字段/排序方向`，确认列表与总数实时变化。
2) 已选批量：勾选几条记忆，分别点击“置顶已选 / 取消置顶已选 / 归档已选 / 恢复已选”，确认列表里的 `status` 与 `PIN` 标记变化。
3) 当前筛选批量：先用来源或类型筛出一批，再点击“归档当前筛选全部 / 恢复当前筛选全部 / 置顶当前筛选全部 / 取消置顶当前筛选全部”，确认操作影响条数与列表结果一致。
4) 删除按筛选精确生效：先用来源（例如 `auto_extract`）筛出一批，点击“删除当前筛选全部”，确认只删除当前筛选命中的那批记忆。

### M5 验证（建议）
1) 打开设置 -> 角色/记忆：确认出现“召回增强（M5）”区块（Tag/向量相关配置）。
2) Tag 召回：先发“我要吃手抓羊肉”，再问“还记得手抓羊肉吗”，应能命中“我要吃手抓羊肉”（不要求完全相同句子）。
3) Tag 扩展：把 “Tag 扩展数” 调大（如 6~12），用更“外壳化”的问法测试（如“你还记得我说过那个羊肉吗”），命中率应更稳。
4) 启用向量（可选）：勾选“启用向量召回”，填写 embeddings 模型与 API（或勾选“向量使用单独 API Key/BaseUrl”），等待后台索引跑一会儿（每 5 秒一批）。
5) 向量召回：用更换说法/同义词测试（例如把“想吃手抓羊肉”改问成“想吃新疆的那种羊肉”），若 embeddings 可用，应能更容易召回相关记忆。
6) 可观测：聊天窗口记忆状态栏应显示“召回 TIME/FTS/LIKE/TAG/VEC”，悬停能看到命中计数与耗时（以及向量是否尝试/失败原因）。

### M6 验证（建议）
1) 设置 -> 角色/记忆：开启“图谱层（M6，可选）”里的 “启用 KG（实体/关系）召回”，并填写 KG 的 BaseUrl/API Key/模型（你要求 M6 单独配置 API）。
2) 等待 30~60 秒（后台每 7 秒一批），然后用“换说法/外壳词”提问：例如先说“我要吃手抓羊肉”，后面问“还记得那个羊肉吗”。
3) 观察聊天窗口状态栏 `召回`：应出现 `KG`（并且悬停能看到 KG 命中条数）。
4) 若一直没有 `KG`：悬停看向量/Tag 的 debug 外，再检查 KG 悬停信息里是否提示 `error=...`（比如 API 配置缺失或模型返回非 JSON）。

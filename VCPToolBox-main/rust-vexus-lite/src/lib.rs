#![deny(clippy::all)]

use napi::bindgen_prelude::*;
use napi_derive::napi;
use std::sync::{Arc, RwLock};
use usearch::Index;
use rusqlite::Connection;

/// æœç´¢ç»“æœ (è¿”å› ID è€Œé Tag æ–‡æœ¬)
/// ä¸Šå±‚ JS ä¼šæ‹¿ç€ ID å» SQLite é‡ŒæŸ¥å…·ä½“çš„æ–‡æœ¬å†…å®¹
#[napi(object)]
pub struct SearchResult {
    pub id: u32,   // å¯¹åº” SQLite ä¸­çš„ chunks.id æˆ– tags.id
    pub score: f64,
}

#[napi(object)]
pub struct SvdResult {
    pub u: Vec<f64>, // æ‰å¹³åŒ–çš„æ­£äº¤åŸºåº•å‘é‡é›† (k * dim)
    pub s: Vec<f64>, // ç‰¹å¾å€¼ (å¥‡å¼‚å€¼)
    pub k: u32,
    pub dim: u32,
}

#[napi(object)]
pub struct OrthogonalProjectionResult {
    pub projection: Vec<f64>,
    pub residual: Vec<f64>,
    pub basis_coefficients: Vec<f64>,
}

#[napi(object)]
pub struct HandshakeResult {
    pub magnitudes: Vec<f64>,
    pub directions: Vec<f64>, // æ‰å¹³åŒ–çš„æ–¹å‘å‘é‡ (n * dim)
}

#[napi(object)]
pub struct ProjectResult {
    pub projections: Vec<f64>,
    pub probabilities: Vec<f64>,
    pub entropy: f64,
    pub total_energy: f64,
}

/// ç»Ÿè®¡ä¿¡æ¯
#[napi(object)]
pub struct VexusStats {
    pub total_vectors: u32,
    pub dimensions: u32,
    pub capacity: u32,
    pub memory_usage: u32,
}

/// æ ¸å¿ƒç´¢å¼•ç»“æ„ (æ— çŠ¶æ€ï¼Œåªå­˜å‘é‡)
#[napi]
pub struct VexusIndex {
    index: Arc<RwLock<Index>>,
    dimensions: u32,
}

#[napi]
impl VexusIndex {
    /// åˆ›å»ºæ–°çš„ç©ºç´¢å¼•
    #[napi(constructor)]
    pub fn new(dim: u32, capacity: u32) -> Result<Self> {
        let index = Index::new(&usearch::IndexOptions {
            dimensions: dim as usize,
            metric: usearch::MetricKind::L2sq, // ä½™å¼¦ç›¸ä¼¼åº¦é€šå¸¸ç”¨ L2sq æˆ– Cosine (å¦‚æœæ˜¯å½’ä¸€åŒ–å‘é‡ï¼ŒL2sq ç­‰ä»·äº Cosine)
            quantization: usearch::ScalarKind::F32,
            connectivity: 16,
            expansion_add: 128,
            expansion_search: 64,
            multi: false,
        })
        .map_err(|e| Error::from_reason(format!("Failed to create index: {:?}", e)))?;

        index
            .reserve(capacity as usize)
            .map_err(|e| Error::from_reason(format!("Failed to reserve capacity: {:?}", e)))?;

        Ok(Self {
            index: Arc::new(RwLock::new(index)),
            dimensions: dim,
        })
    }

    /// ä»ç£ç›˜åŠ è½½ç´¢å¼•
    /// æ³¨æ„ï¼šç§»é™¤äº† map_pathï¼Œå› ä¸ºæ˜ å°„å…³ç³»ç°åœ¨ç”± SQLite ç®¡ç†
    #[napi(factory)]
    pub fn load(index_path: String, _unused_map_path: Option<String>, dim: u32, capacity: u32) -> Result<Self> {
        // ä¸ºäº†ä¿æŒ JS è°ƒç”¨ç­¾åå…¼å®¹ï¼Œä¿ç•™äº† map_path å‚æ•°ä½†å¿½ç•¥å®ƒ
        // æˆ–è€…ä½ å¯ä»¥ä¿®æ”¹ JS é‡Œçš„è°ƒç”¨å»æ‰ç¬¬äºŒä¸ªå‚æ•°

        // åˆ›å»ºç©ºç´¢å¼•é…ç½®
        let index = Index::new(&usearch::IndexOptions {
            dimensions: dim as usize,
            metric: usearch::MetricKind::L2sq,
            quantization: usearch::ScalarKind::F32,
            connectivity: 16,
            expansion_add: 128,
            expansion_search: 64,
            multi: false,
        })
        .map_err(|e| Error::from_reason(format!("Failed to create index wrapper: {:?}", e)))?;

        // åŠ è½½äºŒè¿›åˆ¶æ–‡ä»¶
        index.load(&index_path)
            .map_err(|e| Error::from_reason(format!("Failed to load index from disk: {:?}", e)))?;

        // æ£€æŸ¥å®¹é‡å¹¶æ‰©å®¹
        let current_capacity = index.capacity();
        if capacity as usize > current_capacity {
            // eprintln!("[Vexus] Expanding capacity on load: {} -> {}", current_capacity, capacity);
            index
                .reserve(capacity as usize)
                .map_err(|e| Error::from_reason(format!("Failed to expand capacity: {:?}", e)))?;
        }

        Ok(Self {
            index: Arc::new(RwLock::new(index)),
            dimensions: dim,
        })
    }

    /// ä¿å­˜ç´¢å¼•åˆ°ç£ç›˜
    #[napi]
    pub fn save(&self, index_path: String) -> Result<()> {
        let index = self.index.read()
            .map_err(|e| Error::from_reason(format!("Lock failed: {}", e)))?;
        
        // åŸå­å†™å…¥ï¼šå…ˆå†™ä¸´æ—¶æ–‡ä»¶ï¼Œå†é‡å‘½å
        let temp_path = format!("{}.tmp", index_path);

        index
            .save(&temp_path)
            .map_err(|e| Error::from_reason(format!("Failed to save index: {:?}", e)))?;

        std::fs::rename(&temp_path, &index_path)
            .map_err(|e| Error::from_reason(format!("Failed to rename index file: {}", e)))?;

        Ok(())
    }

    /// å•ä¸ªæ·»åŠ  (JS å¾ªç¯è°ƒç”¨)
    #[napi]
    pub fn add(&self, id: u32, vector: Buffer) -> Result<()> {
        let index = self.index.write()
            .map_err(|e| Error::from_reason(format!("Lock failed: {}", e)))?;

        let vec_slice: &[f32] = unsafe {
            std::slice::from_raw_parts(
                vector.as_ptr() as *const f32,
                vector.len() / std::mem::size_of::<f32>(),
            )
        };

        if vec_slice.len() != self.dimensions as usize {
            return Err(Error::from_reason(format!(
                "Dimension mismatch: expected {}, got {}",
                self.dimensions,
                vec_slice.len()
            )));
        }

        // è‡ªåŠ¨æ‰©å®¹æ£€æŸ¥
        if index.size() + 1 >= index.capacity() {
             let new_cap = (index.capacity() as f64 * 1.5) as usize;
             let _ = index.reserve(new_cap);
        }

        index
            .add(id as u64, vec_slice)
            .map_err(|e| Error::from_reason(format!("Add failed: {:?}", e)))?;

        Ok(())
    }

    /// æ‰¹é‡æ·»åŠ  (æ›´é«˜æ•ˆï¼Œå»ºè®®æœªæ¥ JS æ”¹ç”¨æ­¤æ¥å£)
    #[napi]
    pub fn add_batch(&self, ids: Vec<u32>, vectors: Buffer) -> Result<()> {
        let index = self.index.write()
            .map_err(|e| Error::from_reason(format!("Lock failed: {}", e)))?;

        let count = ids.len();
        let dim = self.dimensions as usize;
        
        let vec_slice: &[f32] = unsafe {
            std::slice::from_raw_parts(
                vectors.as_ptr() as *const f32,
                vectors.len() / std::mem::size_of::<f32>(),
            )
        };

        if vec_slice.len() != count * dim {
             return Err(Error::from_reason("Batch size mismatch".to_string()));
        }

        // é¢„æ‰©å®¹
        if index.size() + count >= index.capacity() {
            let new_cap = ((index.size() + count) as f64 * 1.5) as usize;
            let _ = index.reserve(new_cap);
        }

        for (i, id) in ids.iter().enumerate() {
            let start = i * dim;
            let v = &vec_slice[start..start+dim];
            // remove + add = update (usearch è¡Œä¸º)
            // let _ = index.remove(*id as u64); 
            index.add(*id as u64, v)
                .map_err(|e| Error::from_reason(format!("Batch add failed idx {}: {:?}", i, e)))?;
        }

        Ok(())
    }

    /// æœç´¢
    #[napi]
    pub fn search(&self, query: Buffer, k: u32) -> Result<Vec<SearchResult>> {
        let index = self.index.read()
            .map_err(|e| Error::from_reason(format!("Lock failed: {}", e)))?;

        let query_slice: &[f32] = unsafe {
            std::slice::from_raw_parts(
                query.as_ptr() as *const f32,
                query.len() / std::mem::size_of::<f32>(),
            )
        };

        // ğŸ”¥ğŸ”¥ğŸ”¥ã€æ–°å¢ã€‘ç»´åº¦å®‰å…¨æ£€æŸ¥ ğŸ”¥ğŸ”¥ğŸ”¥
        if query_slice.len() != self.dimensions as usize {
            return Err(Error::from_reason(format!(
                "Search dimension mismatch: expected {}, got {}. (Check your JS Buffer slicing!)",
                self.dimensions,
                query_slice.len()
            )));
        }

        // æ‰§è¡Œæœç´¢
        let matches = index
            .search(query_slice, k as usize)
            .map_err(|e| Error::from_reason(format!("Search failed: {:?}", e)))?;

        let mut results = Vec::with_capacity(matches.keys.len());
        
        for (key, &dist) in matches.keys.iter().zip(matches.distances.iter()) {
            results.push(SearchResult {
                id: *key as u32,
                score: 1.0 - dist as f64, // L2sq è·ç¦»è½¬ç›¸ä¼¼åº¦åˆ†æ•° (è¿‘ä¼¼)
            });
        }

        Ok(results)
    }

    /// åˆ é™¤ (æŒ‰ ID)
    #[napi]
    pub fn remove(&self, id: u32) -> Result<()> {
        let index = self.index.write()
            .map_err(|e| Error::from_reason(format!("Lock failed: {}", e)))?;
        
        index.remove(id as u64)
             .map_err(|e| Error::from_reason(format!("Remove failed: {:?}", e)))?;
             
        Ok(())
    }

    /// è·å–å½“å‰ç´¢å¼•çŠ¶æ€
    #[napi]
    pub fn stats(&self) -> Result<VexusStats> {
        let index = self.index.read()
            .map_err(|e| Error::from_reason(format!("Lock failed: {}", e)))?;

        Ok(VexusStats {
            total_vectors: index.size() as u32,
            dimensions: self.dimensions,
            capacity: index.capacity() as u32,
            memory_usage: index.memory_usage() as u32,
        })
    }

    /// ä» SQLite æ•°æ®åº“æ¢å¤ç´¢å¼• (å¼‚æ­¥ç‰ˆæœ¬ï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹)
    #[napi]
    pub fn recover_from_sqlite(
        &self,
        db_path: String,
        table_type: String,
        filter_diary_name: Option<String>,
    ) -> AsyncTask<RecoverTask> {
        AsyncTask::new(RecoverTask {
            index: self.index.clone(),
            db_path,
            table_type,
            filter_diary_name,
            dimensions: self.dimensions,
        })
    }

    /// é«˜æ€§èƒ½ SVD åˆ†è§£ (ç”¨äº EPA åŸºåº•æ„å»º)
    /// flattened_vectors: n * dim çš„æ‰å¹³åŒ–å‘é‡æ•°ç»„
    /// n: å‘é‡æ•°é‡
    /// max_k: æœ€å¤§ä¿ç•™çš„ä¸»æˆåˆ†æ•°é‡
    #[napi]
    pub fn compute_svd(&self, flattened_vectors: Buffer, n: u32, max_k: u32) -> Result<SvdResult> {
        let dim = self.dimensions as usize;
        let n = n as usize;
        let max_k = max_k as usize;

        let vec_slice: &[f32] = unsafe {
            std::slice::from_raw_parts(
                flattened_vectors.as_ptr() as *const f32,
                flattened_vectors.len() / std::mem::size_of::<f32>(),
            )
        };

        if vec_slice.len() != n * dim {
            return Err(Error::from_reason(format!(
                "Flattened vectors length mismatch: expected {}, got {}",
                n * dim,
                vec_slice.len()
            )));
        }

        // ä½¿ç”¨ nalgebra è¿›è¡Œ SVD åˆ†è§£
        // M æ˜¯ n x dim çŸ©é˜µ
        use nalgebra::DMatrix;
        let matrix = DMatrix::from_row_slice(n, dim, vec_slice);
        
        // è®¡ç®— SVD: M = U * S * V^T
        // æˆ‘ä»¬éœ€è¦çš„æ˜¯ V^T çš„è¡Œï¼Œå®ƒä»¬æ˜¯åŸå§‹ç©ºé—´ä¸­çš„ä¸»æˆåˆ†
        let svd = matrix.svd(false, true);
        
        let s = svd.singular_values.as_slice().iter().map(|&x| x as f64).collect::<Vec<_>>();
        let v_t = svd.v_t.ok_or_else(|| Error::from_reason("Failed to compute V^T matrix".to_string()))?;
        
        let k = std::cmp::min(s.len(), max_k);
        let mut u_flattened = Vec::with_capacity(k * dim);
        
        for i in 0..k {
            let row = v_t.row(i);
            // nalgebra çš„ row view å¯èƒ½ä¸è¿ç»­ï¼Œæ‰‹åŠ¨è¿­ä»£ä»¥ç¡®ä¿å®‰å…¨
            for &val in row.iter() {
                u_flattened.push(val as f64);
            }
        }

        Ok(SvdResult {
            u: u_flattened,
            s: s[..k].to_vec(),
            k: k as u32,
            dim: dim as u32,
        })
    }

    /// é«˜æ€§èƒ½ Gram-Schmidt æ­£äº¤æŠ•å½±
    #[napi]
    pub fn compute_orthogonal_projection(
        &self,
        vector: Buffer,
        flattened_tags: Buffer,
        n_tags: u32,
    ) -> Result<OrthogonalProjectionResult> {
        let dim = self.dimensions as usize;
        let n = n_tags as usize;

        let query: &[f32] = unsafe {
            std::slice::from_raw_parts(vector.as_ptr() as *const f32, vector.len() / 4)
        };
        let tags_slice: &[f32] = unsafe {
            std::slice::from_raw_parts(flattened_tags.as_ptr() as *const f32, flattened_tags.len() / 4)
        };

        if query.len() != dim || tags_slice.len() != n * dim {
            return Err(Error::from_reason("Dimension mismatch".to_string()));
        }

        let mut basis: Vec<Vec<f64>> = Vec::with_capacity(n);
        let mut basis_coefficients = vec![0.0; n];
        let mut projection = vec![0.0; dim];

        for i in 0..n {
            let start = i * dim;
            let tag_vec = &tags_slice[start..start + dim];
            let mut v: Vec<f64> = tag_vec.iter().map(|&x| x as f64).collect();

            for u in &basis {
                let mut dot = 0.0;
                for d in 0..dim {
                    dot += v[d] * u[d];
                }
                for d in 0..dim {
                    v[d] -= dot * u[d];
                }
            }

            let mut mag_sq = 0.0;
            for d in 0..dim {
                mag_sq += v[d] * v[d];
            }
            let mag = mag_sq.sqrt();

            if mag > 1e-6 {
                for d in 0..dim {
                    v[d] /= mag;
                }
                
                let mut coeff = 0.0;
                for d in 0..dim {
                    coeff += (query[d] as f64) * v[d];
                }
                basis_coefficients[i] = coeff.abs();
                
                for d in 0..dim {
                    projection[d] += coeff * v[d];
                }
                basis.push(v);
            }
        }

        let mut residual = vec![0.0; dim];
        for d in 0..dim {
            residual[d] = (query[d] as f64) - projection[d];
        }

        Ok(OrthogonalProjectionResult {
            projection,
            residual,
            basis_coefficients,
        })
    }

    /// é«˜æ€§èƒ½æ¡æ‰‹åˆ†æ
    #[napi]
    pub fn compute_handshakes(&self, query: Buffer, flattened_tags: Buffer, n_tags: u32) -> Result<HandshakeResult> {
        let dim = self.dimensions as usize;
        let n = n_tags as usize;

        let q: &[f32] = unsafe {
            std::slice::from_raw_parts(query.as_ptr() as *const f32, query.len() / 4)
        };
        let tags: &[f32] = unsafe {
            std::slice::from_raw_parts(flattened_tags.as_ptr() as *const f32, flattened_tags.len() / 4)
        };

        let mut magnitudes = Vec::with_capacity(n);
        let mut directions = Vec::with_capacity(n * dim);

        for i in 0..n {
            let start = i * dim;
            let tag_vec = &tags[start..start + dim];
            let mut mag_sq = 0.0;
            let mut delta = vec![0.0; dim];

            for d in 0..dim {
                let diff = (q[d] - tag_vec[d]) as f64;
                delta[d] = diff;
                mag_sq += diff * diff;
            }

            let mag = mag_sq.sqrt();
            magnitudes.push(mag);

            if mag > 1e-9 {
                for d in 0..dim {
                    directions.push(delta[d] / mag);
                }
            } else {
                for _ in 0..dim {
                    directions.push(0.0);
                }
            }
        }

        Ok(HandshakeResult {
            magnitudes,
            directions,
        })
    }

    /// é«˜æ€§èƒ½ EPA æŠ•å½±
    #[napi]
    pub fn project(
        &self,
        vector: Buffer,
        flattened_basis: Buffer,
        mean_vector: Buffer,
        k: u32,
    ) -> Result<ProjectResult> {
        let dim = self.dimensions as usize;
        let k = k as usize;

        let vec: &[f32] = unsafe {
            std::slice::from_raw_parts(vector.as_ptr() as *const f32, vector.len() / 4)
        };
        let basis_slice: &[f32] = unsafe {
            std::slice::from_raw_parts(flattened_basis.as_ptr() as *const f32, flattened_basis.len() / 4)
        };
        let mean: &[f32] = unsafe {
            std::slice::from_raw_parts(mean_vector.as_ptr() as *const f32, mean_vector.len() / 4)
        };

        if vec.len() != dim || basis_slice.len() != k * dim || mean.len() != dim {
            return Err(Error::from_reason("Dimension mismatch".to_string()));
        }

        let mut centered = vec![0.0; dim];
        for d in 0..dim {
            centered[d] = (vec[d] - mean[d]) as f64;
        }

        let mut projections = vec![0.0; k];
        let mut total_energy = 0.0;

        for i in 0..k {
            let start = i * dim;
            let b = &basis_slice[start..start + dim];
            let mut dot = 0.0;
            for d in 0..dim {
                dot += centered[d] * (b[d] as f64);
            }
            projections[i] = dot;
            total_energy += dot * dot;
        }

        let mut probabilities = vec![0.0; k];
        let mut entropy = 0.0;

        if total_energy > 1e-12 {
            for i in 0..k {
                let p = (projections[i] * projections[i]) / total_energy;
                probabilities[i] = p;
                if p > 1e-9 {
                    entropy -= p * p.log2();
                }
            }
        }

        Ok(ProjectResult {
            projections,
            probabilities,
            entropy,
            total_energy,
        })
    }
}

pub struct RecoverTask {
    index: Arc<RwLock<Index>>,
    db_path: String,
    table_type: String,
    filter_diary_name: Option<String>,
    dimensions: u32,
}

impl Task for RecoverTask {
    type Output = u32;
    type JsValue = u32;

    fn compute(&mut self) -> Result<Self::Output> {
        let conn = Connection::open(&self.db_path)
            .map_err(|e| Error::from_reason(format!("Failed to open DB: {}", e)))?;

        let sql: String;
        
        if self.table_type == "tags" {
            sql = "SELECT id, vector FROM tags WHERE vector IS NOT NULL".to_string();
        } else if self.table_type == "chunks" && self.filter_diary_name.is_some() {
            sql = "SELECT c.id, c.vector FROM chunks c JOIN files f ON c.file_id = f.id WHERE f.diary_name = ?1 AND c.vector IS NOT NULL".to_string();
        } else {
            return Ok(0);
        }

        let mut stmt = conn
            .prepare(&sql)
            .map_err(|e| Error::from_reason(format!("Failed to prepare statement: {}", e)))?;

        // å‚æ•°åœ¨ä¸‹é¢çš„ query_map è°ƒç”¨ä¸­ç›´æ¥å¤„ç†ï¼Œè¿™é‡Œä¸å†éœ€è¦å‡†å¤‡ params å˜é‡
        
        // ä¸ºäº†é¿å…å¤æ‚çš„ç”Ÿå‘½å‘¨æœŸé—®é¢˜ï¼Œæˆ‘ä»¬ç®€å•åœ°åˆ†åˆ«å¤„ç†
        let mut count = 0;
        let mut skipped_dim_mismatch = 0;
        let expected_byte_len = self.dimensions as usize * std::mem::size_of::<f32>();
        
        // è·å–å†™é”
        let index = self.index.write()
            .map_err(|e| Error::from_reason(format!("Lock failed: {}", e)))?;

        // å®šä¹‰å¤„ç†å•è¡Œçš„é—­åŒ…
        let mut process_row = |id: i64, vector_bytes: Vec<u8>| {
             if vector_bytes.len() == expected_byte_len {
                let vec_slice: &[f32] = unsafe {
                    std::slice::from_raw_parts(
                        vector_bytes.as_ptr() as *const f32,
                        self.dimensions as usize,
                    )
                };
                
                if index.size() + 1 >= index.capacity() {
                    let new_cap = (index.capacity() as f64 * 1.5) as usize;
                    let _ = index.reserve(new_cap);
                }

                if index.add(id as u64, vec_slice).is_ok() {
                    count += 1;
                }
            } else {
                skipped_dim_mismatch += 1;
            }
        };

        if let Some(name) = &self.filter_diary_name {
            let rows = stmt.query_map([name], |row| Ok((row.get::<_, i64>(0)?, row.get::<_, Vec<u8>>(1)?)))
                .map_err(|e| Error::from_reason(format!("Query failed: {}", e)))?;
            
            for row_result in rows {
                if let Ok((id, vector_bytes)) = row_result {
                    process_row(id, vector_bytes);
                }
            }
        } else {
            let rows = stmt.query_map([], |row| Ok((row.get::<_, i64>(0)?, row.get::<_, Vec<u8>>(1)?)))
                .map_err(|e| Error::from_reason(format!("Query failed: {}", e)))?;
            
            for row_result in rows {
                if let Ok((id, vector_bytes)) = row_result {
                    process_row(id, vector_bytes);
                }
            }
        }
        
        if skipped_dim_mismatch > 0 {
            // è¿™é‡Œä½¿ç”¨ println!ï¼Œå®ƒä¼šè¾“å‡ºåˆ° Node.js çš„ stdout
            println!("[Vexus-Lite] âš ï¸ Skipped {} vectors due to dimension mismatch (Expected {} bytes, got various)", skipped_dim_mismatch, expected_byte_len);
        }

        Ok(count)
    }

    fn resolve(&mut self, _env: Env, output: Self::Output) -> Result<Self::JsValue> {
        Ok(output)
    }
}